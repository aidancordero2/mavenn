{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Protein DMS modeling using a biophysical G-P map V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Special imports\n",
    "import mavenn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to train and visualize a thermodynamic model  describing the folding and IgG-binding of protein GB1 variants. This model was first proposed by Otwinowski (2018), who trained it on the DMS data of Olson et al. (2014). Here we repeat this exercise within the MAVE-NN framework, thus obtaining a model similar to the one featured in Figs. 6a and 6b of Tareen et al. (2021). The mathematical form of this G-P map is explianed in the supplemental material of Tareen et al. (2021); see in particular  Fig. S4a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom G-P map\n",
    "\n",
    "First we define a custom G-P map that represents our biophysical model. We do this by subclassing `CustomGPMapLayer` to get a custom G-P map class called `OtwinowskiGPMapLayer`. This subclassing procedure requires that we fill in the bodies of four specific methods.\n",
    "- `__init__()`: The constructor must take as input and then record at least three specific parameters: `L` (sequence length), `C` (alphabet size), and `theta_regularization` (the strength of G-P map parameter regularization). The constructor must also end by calling `super().__init__(*args, **kwargs)`, which passes all additional arguments to the superclass constructor.\n",
    "- `build()`: This method defines the trainable parameters (i.e., the weights) of the custom G-P map: these are named `theta_f_0`, `theta_b_0`, `theta_f_lc`, and `theta_b_lc`.  TensorFlow provides this method with an argument called `input_shape`, and the superclass method `super().build(input_shape)` must be called before exiting.\n",
    "- `call()`: This is the meat of the custom G-P map. The input `x_lc` is a one-hot encoding of all sequences in a minimatch. It has size `[-1, L, C]`, where the first index runs over minibatch examples. The G-P map parameters are then used to compute and return a vector `phi` of latent phenotype values, one for each input sequence in the minibatch.\n",
    "- `get_parameters()`: This method returns a `dict` object that lists the values of model parameters. Note that these values must be `float` or `np.ndarray` objects, not TensorFlow tensor objects.\n",
    "- `set_parameters()`: This method takes a `dict` of the form returned by `get_parameters()` and sets the values of the the `OtwinowskiGPMapLayer` weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard TensorFlow imports\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "# Import base class\n",
    "from mavenn.src.layers.gpmap import CustomGPMapLayer\n",
    "\n",
    "# Define custom G-P map layer\n",
    "class OtwinowskiGPMapLayer(CustomGPMapLayer):\n",
    "    \"\"\"\n",
    "    A G-P map representing the thermodynamic model described by\n",
    "    Otwinowski (2018).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, L, C, theta_regularization, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Construct layer instance.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set sequence length and alphabet size\n",
    "        self.L = L\n",
    "        self.C = C\n",
    "\n",
    "        # Define L2 regularizer of G-P map parameters\n",
    "        self.regularizer = tf.keras.regularizers.L2(theta_regularization)\n",
    "\n",
    "        # Call superclass constructor\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Define layer parameters.\"\"\"\n",
    "        \n",
    "        # Initialize constant parameter for folding energy\n",
    "        self.theta_f_0 = self.add_weight(name='theta_f_0',\n",
    "                                         shape=(1,),\n",
    "                                         trainable=True,\n",
    "                                         regularizer=self.regularizer)\n",
    "\n",
    "        # Initialize constant parameter for binding energy\n",
    "        self.theta_b_0 = self.add_weight(name='theta_b_0',\n",
    "                                         shape=(1,),\n",
    "                                         trainable=True,\n",
    "                                         regularizer=self.regularizer)\n",
    "\n",
    "        # Initialize additive parameter for folding energy\n",
    "        self.theta_f_lc = self.add_weight(name='theta_f_lc',\n",
    "                                          shape=(1, self.L, self.C),\n",
    "                                          trainable=True,\n",
    "                                          regularizer=self.regularizer)\n",
    "\n",
    "        # Initialize additive parameter for binding energy\n",
    "        self.theta_b_lc = self.add_weight(name='theta_b_lc',\n",
    "                                          shape=(1, self.L, self.C),\n",
    "                                          trainable=True,\n",
    "                                          regularizer=self.regularizer)\n",
    "        \n",
    "        # Call superclass build\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x_lc):\n",
    "        \"\"\"Compute phi given x.\"\"\"\n",
    "\n",
    "        # Thermal energy scale (k_B * T) in units of kcal/mol\n",
    "        kT = 0.62\n",
    "\n",
    "        # Reshape input to samples x length x characters\n",
    "        x_lc = tf.reshape(x_lc, [-1, self.L, self.C])\n",
    "        \n",
    "        # Compute Delta G for binding\n",
    "        Delta_G_b = self.theta_b_0 + \\\n",
    "                    tf.reshape(K.sum(self.theta_b_lc * x_lc, axis=[1, 2]),\n",
    "                               shape=[-1, 1])\n",
    "            \n",
    "        # Compute Delta G for folding\n",
    "        Delta_G_f = self.theta_f_0 + \\\n",
    "                    tf.reshape(K.sum(self.theta_f_lc * x_lc, axis=[1, 2]),\n",
    "                               shape=[-1, 1])\n",
    "        \n",
    "        # Compute and return fraction folded and bound\n",
    "        Z = 1+K.exp(-Delta_G_f/kT)+K.exp(-(Delta_G_f+Delta_G_b)/kT)\n",
    "        p_bf = (K.exp(-(Delta_G_f+Delta_G_b)/kT))/Z\n",
    "        phi = K.log(p_bf)/np.log(2)\n",
    "        return phi\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Get values of layer parameters.\n",
    "        Note: all energy parameter values are in units of kcal/mol\n",
    "        \"\"\"\n",
    "\n",
    "        param_dict = {}\n",
    "        param_dict['theta_b_0'] = np.float(self.theta_b_0)\n",
    "        param_dict['theta_f_0'] = np.float(self.theta_f_0)\n",
    "        param_dict['theta_b_lc'] = np.squeeze(self.theta_b_lc)\n",
    "        param_dict['theta_f_lc'] = np.squeeze(self.theta_f_lc)\n",
    "        return param_dict\n",
    "\n",
    "    def set_params(self, param_dict):\n",
    "        \"\"\"Set values of layer parameters.\"\"\"\n",
    "\n",
    "        #TODO: Fill out set_params function ->Mahdi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training a model with a custom G-P map\n",
    "\n",
    "Next we load the `'gb1'` dataset, compute sequence length, and split the data into a test set and a training+validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'gb1' \n",
      "Sequence length: 55 amino acids\n",
      "Training set   :  477,854 observations (  90.04%)\n",
      "Validation set :   26,519 observations (   5.00%)\n",
      "Test set       :   26,364 observations (   4.97%)\n",
      "-------------------------------------------------\n",
      "Total dataset  :  530,737 observations ( 100.00%)\n",
      "\n",
      "trainval_df:\n"
     ]
    },
    {
     "data": {
      "text/plain": "        validation  dist  input_ct  selected_ct         y  \\\n0            False     2       173           33 -3.145154   \n1            False     2        18            8 -1.867676   \n2            False     2        66            2 -5.270800   \n3            False     2        72            1 -5.979498   \n4            False     2        69          168  0.481923   \n...            ...   ...       ...          ...       ...   \n504368       False     2       462          139 -2.515259   \n504369       False     2       317           84 -2.693165   \n504370       False     2       335           77 -2.896589   \n504371       False     2       148           28 -3.150861   \n504372       False     2        95           16 -3.287173   \n\n                                                        x  \n0       AAKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n1       ACKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n2       ADKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n3       AEKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n4       AFKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n...                                                   ...  \n504368  QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n504369  QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n504370  QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n504371  QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n504372  QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...  \n\n[504373 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>validation</th>\n      <th>dist</th>\n      <th>input_ct</th>\n      <th>selected_ct</th>\n      <th>y</th>\n      <th>x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>2</td>\n      <td>173</td>\n      <td>33</td>\n      <td>-3.145154</td>\n      <td>AAKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>2</td>\n      <td>18</td>\n      <td>8</td>\n      <td>-1.867676</td>\n      <td>ACKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>2</td>\n      <td>66</td>\n      <td>2</td>\n      <td>-5.270800</td>\n      <td>ADKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>2</td>\n      <td>72</td>\n      <td>1</td>\n      <td>-5.979498</td>\n      <td>AEKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>2</td>\n      <td>69</td>\n      <td>168</td>\n      <td>0.481923</td>\n      <td>AFKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>504368</th>\n      <td>False</td>\n      <td>2</td>\n      <td>462</td>\n      <td>139</td>\n      <td>-2.515259</td>\n      <td>QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>504369</th>\n      <td>False</td>\n      <td>2</td>\n      <td>317</td>\n      <td>84</td>\n      <td>-2.693165</td>\n      <td>QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>504370</th>\n      <td>False</td>\n      <td>2</td>\n      <td>335</td>\n      <td>77</td>\n      <td>-2.896589</td>\n      <td>QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>504371</th>\n      <td>False</td>\n      <td>2</td>\n      <td>148</td>\n      <td>28</td>\n      <td>-3.150861</td>\n      <td>QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n    <tr>\n      <th>504372</th>\n      <td>False</td>\n      <td>2</td>\n      <td>95</td>\n      <td>16</td>\n      <td>-3.287173</td>\n      <td>QYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDD...</td>\n    </tr>\n  </tbody>\n</table>\n<p>504373 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose dataset\n",
    "data_name = 'gb1'\n",
    "print(f\"Loading dataset '{data_name}' \")\n",
    "\n",
    "# Load datset\n",
    "data_df = mavenn.load_example_dataset(data_name)\n",
    "\n",
    "# Get and report sequence length\n",
    "L = len(data_df.loc[0,'x'])\n",
    "print(f'Sequence length: {L:d} amino acids')\n",
    "\n",
    "# Split dataset\n",
    "trainval_df, test_df = mavenn.split_dataset(data_df)\n",
    "\n",
    "# Preview trainval_df\n",
    "print('trainval_df:')\n",
    "trainval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the `mavenn.Model` class. In addition to standard keyword arguments for GE regression, we pass keyword arguments specific to the use of our custom G-P map:\n",
    "\n",
    "- `gpmap_type='custom'`: Alerts the `mavenn.Model()` constructor that we wish to use a custom G-P map.\n",
    "- `custom_gpmap=OtwinowskiGPMapLayer`: Specifies the specific class to use for the custom G-P map layer.\n",
    "- `gpmap_kwargs=gpmap_kwargs`: Provides a dictionary of arguments to be passed to the constructor of the custom G-P map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Order the alphabet to match Otwinowski (2018)\n",
    "alphabet = np.array(list('KRHEDNQTSCGAVLIMPYFW'))\n",
    "C = len(alphabet)\n",
    "\n",
    "# define custom gp_map parameters dictionary\n",
    "gpmap_kwargs = {'L':L,\n",
    "                'C':C,\n",
    "                'theta_regularization': 0.0005}\n",
    "\n",
    "# Create model instance\n",
    "model = mavenn.Model(L=L,\n",
    "                     alphabet=alphabet,\n",
    "                     regression_type='GE',\n",
    "                     ge_nonlinearity_type='linear',\n",
    "                     ge_nonlinearity_monotonic=True,\n",
    "                     ge_noise_model_type='SkewedT',\n",
    "                     ge_heteroskedasticity_order=2,\n",
    "                     ge_nonlinearity_hidden_nodes=100,\n",
    "                     eta_regularization=0.0001,\n",
    "                     gpmap_type='custom',\n",
    "                     normalize_phi=False,\n",
    "                     custom_gpmap=OtwinowskiGPMapLayer,\n",
    "                     gpmap_kwargs=gpmap_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous tutorials, we then set the training data using `model.set_data()` and then train the model using `model.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 504,373 observations set as training data.\n",
      "Using 5.3% for validation.\n",
      "Data shuffled.\n",
      "Time to set data: 8.41 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0epoch [00:00, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24741889017841bb9c415ae380115bb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-d350e84200b7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# Train model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m model.fit(learning_rate=.0005,\n\u001B[0m\u001B[1;32m      8\u001B[0m           \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m           \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/github/mavenn/mavenn/src/error_handling.py\u001B[0m in \u001B[0;36mwrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m             \u001B[0;31m# Execute function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m             \u001B[0;31m# If running functional test and expect to fail\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/github/mavenn/mavenn/src/model.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, epochs, learning_rate, validation_split, verbose, early_stopping, early_stopping_patience, batch_size, linear_initialization, freeze_theta, callbacks, try_tqdm, optimizer, optimizer_kwargs, fit_kwargs)\u001B[0m\n\u001B[1;32m    827\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    828\u001B[0m         \u001B[0;31m# Train neural network using TensorFlow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 829\u001B[0;31m         history = self.model.model.fit(x_train,\n\u001B[0m\u001B[1;32m    830\u001B[0m                                        \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    831\u001B[0m                                        \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3_arm64/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Set training data\n",
    "model.set_data(x=trainval_df['x'],\n",
    "               y=trainval_df['y'],\n",
    "               validation_flags=trainval_df['validation'])\n",
    "\n",
    "# Train model\n",
    "model.fit(learning_rate=.0005,\n",
    "          epochs=1000,\n",
    "          batch_size=300,\n",
    "          early_stopping=True,\n",
    "          early_stopping_patience=100,\n",
    "          linear_initialization=False,\n",
    "          verbose=False);\n",
    "\n",
    "# Save model to file\n",
    "model_name = f'{data_name}_thermodynamic_linreg_model'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we evaluate the performance of the model on test data and save the model to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing models with custom G-P maps\n",
    "\n",
    "One can load the custom G-P map model and analyze its training history / performance in the same way as with built-in G-P map, e.g.:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load model from file\n",
    "model_name = f'{data_name}_thermodynamic_linreg_model'\n",
    "model = mavenn.load(model_name)\n",
    "\n",
    "# Compute variational information on test data\n",
    "I_var, dI_var =  model.I_variational(x=test_df['x'], y=test_df['y'])\n",
    "print(f'test_I_var: {I_var:.3f} +- {dI_var:.3f} bits')\n",
    "\n",
    "# Compute predictive information on test data\n",
    "I_pred, dI_pred = model.I_predictive(x=test_df['x'], y=test_df['y'])\n",
    "print(f'test_I_pred: {I_pred:.3f} +- {dI_pred:.3f} bits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get quantities to plot\n",
    "y_test = test_df['y']\n",
    "N_test = len(y_test)\n",
    "yhat_test = model.x_to_yhat(test_df['x'])\n",
    "phi_test = model.x_to_phi(test_df['x'])\n",
    "phi_lim = [-10, 0]\n",
    "phi_grid = np.linspace(phi_lim[0], phi_lim[1], 1000)\n",
    "yhat_grid = model.phi_to_yhat(phi_grid)\n",
    "q = [0.025, 0.975]\n",
    "yqs_grid = model.yhat_to_yq(yhat_grid, q=q)\n",
    "ix = np.random.choice(a=N_test, size=5000, replace=False)\n",
    "Rsq = np.corrcoef(yhat_test.ravel(), test_df['y'])[0, 1]**2\n",
    "\n",
    "# Create figure and axes for plotting\n",
    "fig, axs = plt.subplots(1,3,figsize=[15,5])\n",
    "\n",
    "# Plot panel 1: Training history\n",
    "ax = axs[0]\n",
    "ax.plot(model.history['I_var'],\n",
    "        label=r'I_var_train')\n",
    "ax.plot(model.history['val_I_var'],\n",
    "        label=r'val_I_var')\n",
    "ax.axhline(I_pred, color='C3', linestyle=':',\n",
    "           label=r'test_I_pred')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('bits')\n",
    "ax.set_title('Training history')\n",
    "ax.legend()\n",
    "\n",
    "## Panel 2: R^2 model performance\n",
    "ax = axs[1]\n",
    "ax.scatter(yhat_test[ix], y_test[ix], color='C0', s=10, alpha=.3,\n",
    "           label='test data')\n",
    "#xlim = [min(yhat_test), max(yhat_test)]\n",
    "#ax.plot(xlim, xlim, '--', color='k', label='diagonal', zorder=100)\n",
    "ax.fill_between(yhat_grid, yqs_grid[:, 0], yqs_grid[:, 1],\n",
    "                alpha=0.2, color='C1', lw=0, label='95% CI of $p(y|\\hat{y})$')\n",
    "ax.plot(yhat_grid, yhat_grid,\n",
    "        linewidth=3, color='C1', label='diagonal')\n",
    "ax.set_xlabel('model prediction ($\\hat{y}$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title(f'Model performance: $R^2$={Rsq:.3}');\n",
    "ax.legend()\n",
    "\n",
    "## Panel 3: GE plot\n",
    "ax = axs[2]\n",
    "ax.scatter(phi_test[ix], y_test[ix],\n",
    "           color='C0', s=10, alpha=.3, label='test data')\n",
    "ax.fill_between(phi_grid, yqs_grid[:, 0], yqs_grid[:, 1],\n",
    "                alpha=0.2, color='C1', lw=0, label='95% CI of $p(y|\\phi)$')\n",
    "ax.plot(phi_grid, yhat_grid,\n",
    "        linewidth=3, color='C1', label='nonlinearity')\n",
    "ax.set_ylim([min(y_test), max(y_test)])\n",
    "ax.set_xlim(phi_lim)\n",
    "ax.set_xlabel('latent phenotype ($\\phi$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title('GE measurement process')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the parameters of our custom G-P map, we again use the method `model.get_theta()`. This returns the dictionary provided by our custom G-P map via the method `get_params()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve G-P map parameter dict and view dict keys\n",
    "theta_dict = model.layer_gpmap.get_params()\n",
    "theta_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the additive parameters that determine both folding energy(`theta_b_lc`) and binding energy (`theta_r_lc`). Note that we visualize these as parameters as changes (`ddG_f` and `ddG_b`) with respect to the wild-type sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the wild-type GB1 sequence\n",
    "wt_seq = model.x_stats['consensus_seq']\n",
    "\n",
    "# Convert this to a one-hot encoded matrix of size LxC\n",
    "from mavenn.src.utils import _x_to_mat\n",
    "x_lc_wt = _x_to_mat(wt_seq, model.alphabet)\n",
    "\n",
    "# Subtract wild-type character value from parameters at each position\n",
    "ddG_b = theta_dict['theta_b_lc'] - np.sum(x_lc_wt*theta_dict['theta_b_lc'], axis=1)[:,np.newaxis]\n",
    "ddG_f = theta_dict['theta_f_lc'] - np.sum(x_lc_wt*theta_dict['theta_f_lc'], axis=1)[:,np.newaxis]\n",
    "\n",
    "# Create figure\n",
    "fig, axs = plt.subplots(2,1, figsize=(12,10))\n",
    "\n",
    "# Set shared keyword arguments for heatmap\n",
    "heatmap_kwargs = {\n",
    "    'alphabet':model.alphabet,\n",
    "    'seq':wt_seq,\n",
    "    'seq_kwargs':{'c':'gray', 's':25},\n",
    "    'cmap':'PiYG',\n",
    "    'cbar':True,\n",
    "    'clim':[-3,3],\n",
    "    'cmap_size':'2%',\n",
    "    'cmap_pad':.3,\n",
    "    'ccenter':0\n",
    "}\n",
    "\n",
    "# Draw binding energy heatmap\n",
    "heatmap_ax, cb = mavenn.heatmap(ax=axs[0], values=ddG_b, **heatmap_kwargs)\n",
    "heatmap_ax.tick_params(axis='y', which='major', pad=10)\n",
    "heatmap_ax.set_xlabel('position ($l$)')\n",
    "heatmap_ax.set_ylabel('amino acid ($c$)')\n",
    "heatmap_ax.set_title(f'Binding energy matrix')\n",
    "cb.outline.set_visible(False)\n",
    "cb.ax.tick_params(direction='in', size=20, color='white')\n",
    "cb.set_label('$\\Delta \\Delta G_B$ (kcal/mol)', labelpad=5, rotation=-90, ha='center', va='center')\n",
    "\n",
    "# Draw folding energy heatmap\n",
    "heatmap_ax, cb = mavenn.heatmap(ax=axs[1], values=ddG_f, **heatmap_kwargs)\n",
    "heatmap_ax.tick_params(axis='y', which='major', pad=10)\n",
    "heatmap_ax.set_xlabel('position ($l$)')\n",
    "heatmap_ax.set_ylabel('amino acid ($c$)')\n",
    "heatmap_ax.set_title(f'Folding energy matrix')\n",
    "cb.outline.set_visible(False)\n",
    "cb.ax.tick_params(direction='in', size=20, color='white')\n",
    "cb.set_label('$\\Delta \\Delta G_F$ (kcal/mol)', labelpad=5, rotation=-90, ha='center', va='center')\n",
    "\n",
    "# Adjust figure and show\n",
    "fig.tight_layout(w_pad=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we compare our thermodynamic model's folding energy predictions to the $\\Delta \\Delta G_F$ measurements of Nisthal et al. (2019)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Otwinowski parameters\n",
    "dG_b_ot_df = pd.read_csv('../../mavenn/examples/datasets/raw/otwinowski_gb_data.csv.gz', index_col=[0]).T.reset_index(drop=True)\n",
    "dG_f_ot_df = pd.read_csv('../../mavenn/examples/datasets/raw/otwinowski_gf_data.csv.gz', index_col=[0]).T.reset_index(drop=True)\n",
    "\n",
    "# Reorder columns\n",
    "dG_b_ot_df = dG_b_ot_df[model.alphabet]\n",
    "dG_f_ot_df = dG_f_ot_df[model.alphabet]\n",
    "\n",
    "# Compute ddG matrices for Otwinowski\n",
    "ddG_b_mat_ot = np.array(dG_b_ot_df - np.sum(x_lc_wt*dG_b_ot_df, axis=1)[:,np.newaxis])\n",
    "ddG_f_mat_ot = np.array(dG_f_ot_df - np.sum(x_lc_wt*dG_f_ot_df, axis=1)[:,np.newaxis])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Create figure\n",
    "fig, axs = plt.subplots(2,1, figsize=(12,10))\n",
    "\n",
    "# Set shared keyword arguments for heatmap\n",
    "heatmap_kwargs = {\n",
    "    'alphabet':model.alphabet,\n",
    "    'seq':wt_seq,\n",
    "    'seq_kwargs':{'c':'gray', 's':25},\n",
    "    'cmap':'PiYG',\n",
    "    'cbar':True,\n",
    "    'clim':[-8,8],\n",
    "    'cmap_size':'2%',\n",
    "    'cmap_pad':.3,\n",
    "    'ccenter':0\n",
    "}\n",
    "\n",
    "# Draw binding energy heatmap\n",
    "heatmap_ax, cb = mavenn.heatmap(ax=axs[0], values=ddG_b_mat_ot, **heatmap_kwargs)\n",
    "heatmap_ax.tick_params(axis='y', which='major', pad=10)\n",
    "heatmap_ax.set_xlabel('position ($l$)')\n",
    "heatmap_ax.set_ylabel('amino acid ($c$)')\n",
    "heatmap_ax.set_title(f'Binding energy matrix')\n",
    "cb.outline.set_visible(False)\n",
    "cb.ax.tick_params(direction='in', size=20, color='white')\n",
    "cb.set_label('$\\Delta \\Delta G_B$ (kcal/mol)', labelpad=5, rotation=-90, ha='center', va='center')\n",
    "\n",
    "# Draw folding energy heatmap\n",
    "heatmap_ax, cb = mavenn.heatmap(ax=axs[1], values=ddG_f_mat_ot, **heatmap_kwargs)\n",
    "heatmap_ax.tick_params(axis='y', which='major', pad=10)\n",
    "heatmap_ax.set_xlabel('position ($l$)')\n",
    "heatmap_ax.set_ylabel('amino acid ($c$)')\n",
    "heatmap_ax.set_title(f'Folding energy matrix')\n",
    "cb.outline.set_visible(False)\n",
    "cb.ax.tick_params(direction='in', size=20, color='white')\n",
    "cb.set_label('$\\Delta \\Delta G_F$ (kcal/mol)', labelpad=5, rotation=-90, ha='center', va='center')\n",
    "\n",
    "# Adjust figure and show\n",
    "fig.tight_layout(w_pad=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot Otwinowski parameters against our parameters\n",
    "fig, axs = plt.subplots(2,1, figsize=(12,10))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.scatter(ddG_b_mat_ot.ravel(), ddG_b.ravel())\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(ddG_f_mat_ot.ravel(), ddG_f.ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load Nisthal data\n",
    "nisthal_df = mavenn.load_example_dataset('nisthal')\n",
    "nisthal_df.set_index('x', inplace=True)\n",
    "\n",
    "# Get Nisthal folding energies relative to WT\n",
    "dG_f_nisthal = nisthal_df['y']\n",
    "dG_f_wt_nisthal = dG_f_nisthal[wt_seq]\n",
    "ddG_f_nisthal = dG_f_nisthal - dG_f_wt_nisthal\n",
    "\n",
    "# Get MAVE-NN folding energies relative to WT\n",
    "x_nisthal = nisthal_df.index.values\n",
    "x_nisthal_ohe = mavenn.src.utils.x_to_ohe(x=x_nisthal,\n",
    "                                          alphabet=model.alphabet)\n",
    "ddG_f_vec = ddG_f.ravel().reshape([1,-1])\n",
    "ddG_f_mavenn = np.sum(ddG_f_vec*x_nisthal_ohe, axis=1)\n",
    "\n",
    "# Get Otwinowski folding energies relative to WT\n",
    "ddG_f_vec_ot = ddG_f_mat_ot.ravel().reshape([1,-1])\n",
    "ddG_f_ot = np.sum(ddG_f_vec_ot*x_nisthal_ohe, axis=1)\n",
    "\n",
    "# Compute R^2\n",
    "Rsq_mavenn = np.corrcoef(ddG_f_mavenn, ddG_f_nisthal)[0, 1]**2\n",
    "Rsq_ot = np.corrcoef(ddG_f_ot, ddG_f_nisthal)[0, 1]**2\n",
    "\n",
    "# Make figure\n",
    "fig, axs = plt.subplots(1,2,figsize=[10,5])\n",
    "xlim = [-3,5]\n",
    "ylim = [-4,8]\n",
    "\n",
    "# Plot Otwinowski vs Nisthal\n",
    "ax = axs[0]\n",
    "ax.scatter(ddG_f_nisthal, 0.62*ddG_f_ot, alpha=.2, label='data')\n",
    "ax.scatter(0,0, label='WT sequence')\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.plot(xlim, xlim, color='k', alpha=.5, label='diagonal')\n",
    "ax.set_xlabel('Nisthal $\\Delta \\Delta G_f$ (kcal/mol)')\n",
    "ax.set_ylabel('Otwinowski $\\Delta \\Delta G_f$ (kcal/mol)')\n",
    "ax.set_title(f'$R^2$ = {Rsq_ot:.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# Plot MAVE-NN vs Nisthal\n",
    "ax = axs[1]\n",
    "ax.scatter(ddG_f_nisthal, ddG_f_mavenn, alpha=.2, label='data')\n",
    "ax.scatter(0,0, label='WT sequence')\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.plot(xlim, xlim, color='k', alpha=.5, label='diagonal')\n",
    "ax.set_xlabel('Nisthal $\\Delta \\Delta G_f$ (kcal/mol)')\n",
    "ax.set_ylabel('MAVE-NN $\\Delta \\Delta G_f$ (kcal/mol)')\n",
    "ax.set_title(f'$R^2$ = {Rsq_mavenn:.3f}')\n",
    "ax.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Otwinowski, J. Biophysical Inference of Epistasis and the Effects of Mutations on Protein Stability and Function. Mol Biol Evol 35, 2345–2354 (2018).\n",
    "\n",
    "2. Olson, C. A., Wu, N. C., Sun, R. A comprehensive biophysical description of pairwise epistasis throughout an entire protein domain. Curr Biol 24, 2643–2651 (2014).\n",
    "\n",
    "3. Tareen, A., Posfai, A., Ireland, W. T., McCandlish, D. M. & Kinney, J. B. MAVE-NN: learning genotype-phenotype maps from multiplex assays of variant effect. bioRxiv doi:10.1101/2020.07.14.201475 (2020).\n",
    "\n",
    "4. Nisthal, A., Wang, C. Y., Ary, M. L., Mayo, S. L. Protein stability engineering insights revealed by domain-wide comprehensive mutagenesis. Proc Natl Acad Sci 116, 16367–16377 (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}