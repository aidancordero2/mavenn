{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training a pairwise G-P map on MPSA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# For showing images\n",
    "from IPython.display import Image\n",
    "\n",
    "# Insert path to mavenn beginning of path\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "# Load mavenn\n",
    "import mavenn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will train a G-P map on data from a massivley parallel splicing assay (MPSA) performed by Wong et al., 2018. Wong et al. mesured splicing activity for nearly all 5' splice sites of the form 'NNN/GYNNNN', where 'Y' denotes any pyrimidine ('C' or 'U'), and '/' denotes the exon/intron boundary.  This was accomplished using the experimental setup illustrated in the following figure. \n",
    "\n",
    "<img src=\"fig_tutorial1_fig1.png\" alt=\"MPSA experiment\" style=\"width: 600px;\"/>\n",
    "\n",
    "Specifically, the authors used a minigene expression system where each variant 5' splice site was tagged with a 20 nucleotide barcode. Constructs were transfected into cell culture, and the fraction of processed transcripts containing the central exon (which the variant 5' splice sites flank). The resulting dataset conisted of a list of assayed splice sites, each assigned a percent-spliced-in (PSI) value. Our goal is to model log PSI values as a function of sequence. \n",
    "\n",
    "We begin by loading data from this assay. This is provided as an example dataset within MAVE-NN, and can be loaded as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splice sites assayed: 31,197.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.427684</td>\n",
       "      <td>AAAGCAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.162168</td>\n",
       "      <td>AAAGCAAAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.121273</td>\n",
       "      <td>AAAGCAAAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>AAAGCAAAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.260932</td>\n",
       "      <td>AAAGCAACA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y          x\n",
       "0 -0.427684  AAAGCAAAA\n",
       "1 -0.162168  AAAGCAAAC\n",
       "2 -0.121273  AAAGCAAAG\n",
       "3 -0.353582  AAAGCAAAU\n",
       "4 -0.260932  AAAGCAACA"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data as a pandas DataFrame\n",
    "data_df = mavenn.load_example_dataset('mpsa')\n",
    "\n",
    "# Show dataset size\n",
    "print(f'Number of splice sites assayed: {len(data_df):,d}.')\n",
    "\n",
    "# Preview dataset\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, $x$ denotes splice site sequences and $y$ denotes log PSI values (which the experiment determins up to an uncertain additive shift). We next extract the data from this dataframe and split into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 24,957 observations\n",
      "Test set size    :  6,240 observations\n"
     ]
    }
   ],
   "source": [
    "# Extract x and y as Numpy arrays\n",
    "x = data_df['x'].values\n",
    "y = data_df['y'].values\n",
    "\n",
    "# Split data 80/20 into training / test sets. \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20)\n",
    "\n",
    "# Show dataset sizes\n",
    "print(f'Training set size: {len(x_train):6,d} observations')\n",
    "print(f'Test set size    : {len(x_test):6,d} observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a MAVE-NN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and set training data\n",
    "model = mavenn.Model(x=x_train, \n",
    "                     y=y_train,\n",
    "                     alphabet='rna',\n",
    "                     gpmap_type='pairwise',\n",
    "                     regression_type='GE',\n",
    "                     ge_noise_model_type='Gaussian',\n",
    "                     ge_heteroskedasticity_order=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall form of this model is schematized in the following figure.\n",
    "\n",
    "<img src=\"fig_tutorial1_fig2.png\" alt=\"Modeling assumptions\" style=\"width: 600px;\"/>\n",
    "\n",
    "In addition to specifying the training inputs (`x=x_train`) and training labels (`y=y_train`), five additional parameters are set. \n",
    "\n",
    "`alphabet='rna'`: This indicates that sequences are made up of the characters 'A', 'C', 'G', 'U'. \n",
    "\n",
    "`gpmap_type='pairwise'`: This indicates that we want to fit a pairwise model for the latent phenotype $\\phi$, i.e. a model of the mathematical form\n",
    "\n",
    "$$ \\phi(x) = \\theta_0 + \\sum_{l,c} \\theta_{l:c} x_{l:c} + \\sum_{l,l'>l} \\sum_{c,c'} \\theta_{l:c,l':c'} x_{l:c} x_{l':c'}$$\n",
    "\n",
    "where $l$ indexes positions in the sequence, $c$ indexes characters from the alphabet, and $x_{l:c}$ is an indicator variable equal to 1 when $c$ occurs at position $l$, and equal to 0 otherwise. The parameters of this model $\\theta_0, \\theta_{l:c}, \\theta_{l:c,l':c'}$ are to be learned from data. \n",
    "\n",
    "`regression_type='GE'`: This indicates that we want to perform global epistasis (GE) regression. The key assumption of GE regression is that each measurement $y$ is a noisy readout of a predicte mesurement $\\hat{y}$, which itself is a nonlinear function $g$ of the latent phenotype $\\phi$. Thus,\n",
    "\n",
    "$$ p(y | \\phi) = p(y|\\hat{y})~~\\mathrm{where}~~\\hat{y} = g(\\phi).$$\n",
    "\n",
    "The nonlinear function $g(\\phi)$ is to be learned from data using a two-layer neural network having a default value of `ge_nonlinearity_hidden_nodes=50` hidden nodes. \n",
    "\n",
    "`ge_noise_model_type='Gaussian'`: This indicates that we wish for our noise model, $p(y|\\hat{y})$, to be a Gaussian distribution. \n",
    "\n",
    "`ge_heteroskedasticitiy_order=2`: This indicates that we are using a heteroskedastic model. Specifically, we model the standard deviation $s$ of $p(y|\\hat{y})$  an expoentiated quadratic polynomial in $\\hat{y}$,\n",
    "\n",
    "$$ s(\\hat{y}) = \\exp \\left[ a_0 + a_1 \\hat{y} + a_2 \\hat{y}^2 \\right], $$\n",
    "\n",
    "where the coefficients $a_0, a_1, a_2$ are to be learned from data. \n",
    "\n",
    "To fit this model to training data, we do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit model to training data. Takes ~15 seconds\n",
    "history = model.fit(epochs=20, learning_rate=.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `history` is the standard history object returned by TensorFlow. It contains the training loss and validation loss values as a function of training epoch, which can be visualized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training loss and validation loss\n",
    "loss_training = history.history['loss']\n",
    "loss_validation = history.history['val_loss']\n",
    "\n",
    "# Plot training history\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_training, color='C2', label='training')\n",
    "ax.plot(loss_validation, color='C3', label='validation')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title(f\"training history\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess model performance, we compute the correlation between $\\hat{y}$ and $y$ on training data. To get values for $\\hat{y}$, we use the method `model.x_to_yhat()`, which returns a numpy array the same shape as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict measurement values (yhat) from sequence (x)\n",
    "yhat_test = model.x_to_yhat(x_test)\n",
    "print(f'yhat_test: {repr(yhat_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot $y$ against $\\hat{y}$ and compute the corresponding $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R^2 between yhat and y_test\n",
    "Rsq = np.corrcoef(yhat_test.ravel(), y_test)[0, 1]**2\n",
    "\n",
    "# Plot y_test vs. yhat_test\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(yhat_test, y_test, color='C0', s=5, alpha=.2, label='test data')\n",
    "ax.set_xlabel('model prediction ($\\hat{y}$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title(f'performance ($R^2$={Rsq:.3})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that instead of using `model.x_to_yhat()`, we can alternatively use `model.x_to_phi()` to first predict latent phenotype values $\\phi$ from input sequences $x$, then use these $\\phi$ to compute $\\hat{y}$ values via `model.phi_to_yhat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict latent phenotype values (phi) from sequence (x)\n",
    "phi_test = model.x_to_phi(x_test)\n",
    "print(f'phi_test: {repr(phi_test)}')\n",
    "\n",
    "# Predict measurement values (yhat) from latent phenotype (phi)\n",
    "yhat_test = model.phi_to_yhat(phi_test)\n",
    "print(f'yhat_test: {repr(yhat_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth plotting measurements $y$ against the predicted latent phenotypes $\\phi$. On the same plot we can show the nonlineairty $g(\\phi)$ by creating a grid of $\\phi$ values and mapping these to $\\hat{y}$ values using `model.phi_to_yhat()`. When doing this, it often makes sense to further plot confidence intervals of $p(y|\\hat{y})$ using the function `model.yhat_to_yq()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of phi values for plotting the GE nonlinearity\n",
    "phi_lim = [min(phi_test)-.5, max(phi_test)+.5]\n",
    "phi_grid = np.linspace(phi_lim[0], phi_lim[1], 1000)\n",
    "\n",
    "# Compute yhat for each phi gridpoint\n",
    "yhat_grid = model.phi_to_yhat(phi_grid)\n",
    "\n",
    "# Compute 68% confidence interval in y for each value of yhat\n",
    "yqs_grid = model.yhat_to_yq(yhat_grid, q=[0.16,0.84])\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(phi_test, y_test, color='C0', s=5, alpha=.2, label='test data')\n",
    "ax.plot(phi_grid, yhat_grid, linewidth=2, color='C1',\n",
    "        label='$\\hat{y} = g(\\phi)$')\n",
    "ax.plot(phi_grid, yqs_grid[:,0], linestyle='--', color='C1', label='68% CI')\n",
    "ax.plot(phi_grid, yqs_grid[:,1], linestyle='--', color='C1')\n",
    "ax.set_xlim(phi_lim)\n",
    "ax.set_xlabel('latent phenotype ($\\phi$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title('measurement process')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong sigmoidal nonlinearities like the one we find here are very common on MAVE experiments and it is critically important that one account for them when trying to model G-P maps. Note also that, in this case, we find that the standard deviation of $y$ about $\\hat{y}$ decreases at larger $\\hat{y}$ values. This illustrates the utility of infering a heteroskedastic noise model. \n",
    "\n",
    "Ultimately we want to view the parameters of the G-P map. MAVE-NN provides two methods to support such visualization, `mavenn.heatmap()` and `mavenn.pairwise_heatmap()`. First we retrieve the additive parameters $\\theta_{l:c}$ in dataframe format using `get_additive_parameters()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values of additive parameters\n",
    "additive_df = model.get_gpmap_parameters(which=\"additive\")\n",
    "additive_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we draw these using `mavenn.heatmap()`. Since all assayed sequences were of the form NNNGYNNNN, we additionally mask the parameters for 'A','C','U' at position 3 and for 'A','G' at position 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate additive parameters as a heatmap\n",
    "fig, ax = plt.subplots(1,1)\n",
    "mask_dict = {3:'ACU',4:'AG'}\n",
    "ax, cb = mavenn.heatmap(df=additive_df,\n",
    "                        mask_dict=mask_dict, \n",
    "                        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mask_dict` can also be determined computationally from the training sequences using `model.get_mask_dict()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mask_dict from trainig data\n",
    "mask_dict = mavenn.get_mask_dict(x_train, alphabet='rna')\n",
    "mask_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we retrieve the additive parameters $\\theta_{l:c,l':c'}$ in dataframe format using `get_pairwise_parameters()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values of all model parameters, including pairwise parameters\n",
    "pairwise_df = model.get_gpmap_parameters(which=\"pairwise\")\n",
    "pairwise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then draw thse using `mavenn.pairwise_heatmap()`, again with the specified mask in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate pairwise parameters\n",
    "fig, ax = plt.subplots(1,1, figsize=[9,5])\n",
    "ax, cb = mavenn.heatmap_pairwise(pairwise_df, \n",
    "                                 mask_dict=mask_dict, \n",
    "                                 ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way of interrogating model parameters is to compute the effects of mutations from a specific wild-type sequence of interest. In this case we will use the consensus splice site `\"CAGGUAAGU\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_ss = \"CAGGUAAGU\"\n",
    "\n",
    "effects_df = mavenn.get_1pt_effects(model.x_to_phi, wt_seq=cons_ss, alphabet=\"rna\")\n",
    "effects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, cb = mavenn.heatmap(df=effects_df,\n",
    "                        seq=cons_ss,\n",
    "                        seq_kwargs={'s':100, 'marker':'o', 'color':'k'},\n",
    "                        l_col=\"l\",\n",
    "                        c_col=\"c_mut\",\n",
    "                        value_col=\"dphi\",\n",
    "                        missing_values=0,\n",
    "                        clim=[-2.5,1],\n",
    "                        ccenter=0,\n",
    "                        mask_dict=mask_dict)\n",
    "ax.set_title(f'consus sequence: {cons_ss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, all mutations away from the consensus sequence reduce $\\phi$, which quantifies splice site strength.\n",
    "\n",
    "Similarly, the effects of pairwise mutations can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects_df = mavenn.get_2pt_effects(model.x_to_phi, wt_seq=cons_ss, alphabet=\"rna\")\n",
    "effects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate pairwise parameters\n",
    "fig, ax = plt.subplots(1,1, figsize=[9,5])\n",
    "ax, cb = mavenn.heatmap_pairwise(effects_df, \n",
    "                                 l1_col=\"l1\",\n",
    "                                 l2_col=\"l2\",\n",
    "                                 c1_col=\"c1_mut\",\n",
    "                                 c2_col=\"c2_mut\",\n",
    "                                 value_col=\"ddphi\",\n",
    "                                 mask_dict=mask_dict,\n",
    "                                 seq=cons_ss,\n",
    "                                 ccenter=0,\n",
    "                                 seq_kwargs={'s':10, 'marker':'o', 'color':'k'},\n",
    "                                 ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
