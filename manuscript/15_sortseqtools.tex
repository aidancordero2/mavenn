%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
%\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails
\usepackage{multirow}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\def\includegraphic{}
\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs

\newcommand{\eq}[1]{Eq.\ (\ref{#1})}
\newcommand{\fig}[2]{Fig.\ \ref{#1}#2}
\newcommand{\diag}{{\rm diag}}
\newcommand{\var}{{\rm var}}
\newcommand{\cov}{{\rm cov}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\beas}{\begin{eqnarray*}}
\newcommand{\eeas}{\end{eqnarray*}}
\newcommand{\data}{{\rm data}}
\newcommand{\real}{{\rm real}}
\newcommand{\die}{\mathrm{die}}
\newcommand{\live}{\mathrm{live}}
\newcommand{\Lap}{\mathrm{Lap}}
\newcommand{\sym}{\{ \mathrm{sym~factor} \}}
\newcommand{\const}{{\rm const}}
\newcommand{\true}{\mathrm{true}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ev}[1]{\left. #1 \right|} 
\newcommand{\bra}[1]{\left\langle #1 \right|}
\newcommand{\ket}[1]{\left| #1 \right\rangle}
\newcommand{\braket}[1]{\left\langle #1 \right\rangle}
\newcommand{\bbraket}[1]{\left\llangle #1 \right\rrangle}
\newcommand{\mat}[2]{\left( \begin{array}{#1} #2 \end{array} \right)}
\newcommand{\bracemat}[2]{\left\{ \begin{array}{#1} #2 \end{array} \right\}}

\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Sort-Seq Tools: software for analyzing massively parallel experiments on mutagenized sequences}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   email={wireland@caltech.edu}   % email address
]{\inits{WI}\fnm{William} \snm{Ireland}}
\author[
   addressref={aff2},
   email={phillips@pboc.caltech.edu}
]{\inits{RP}\fnm{Rob} \snm{Phillips}}
\author[
   addressref={aff3},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff3},                       % id of corresponding address, if any
   email={jkinney@cshl.edu}   % email address
]{\inits{JBK}\fnm{Justin B} \snm{Kinney}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{Department of Physics, California Institute of Technology}, % university, etc
  %\street{Waterloo Road},                     %
  \postcode{91125},                                % post or zip code
  \city{Pasadena},                              % city
  \cny{CA}                                    % country
}
\address[id=aff2]{%                          
  \orgname{Department of Applied Physics, California Institute of Technology}, 
  %\street{Waterloo Road},                    
  \postcode{91125},                               
  \city{Pasadena},                        
  \cny{CA}                                  
}
\address[id=aff3]{%
  \orgname{Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory},
  %\street{1 Bungtown Rd.},
  \postcode{11375},
  \city{Cold Spring Harbor},
  \cny{NY}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
%\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract (100 words or less)
We introduce Sort-Seq Tools, a software package for analyzing a variety of massively parallel experiments on  mutagenized sequences. Such experiments include Sort-Seq studies of bacterial promoters, massively parallel reporter assays of mammalian enhancers, and deep mutational scanning experiments of proteins.  Methods for data simulation, data preprocessing, sequence analysis, quantitative modeling, and visualization are provided. These functionalities are available through a command-line interface, as well as through a Python module, \texttt{sortseq}, that is available on PyPI. Example applications of Sort-Seq Tools in the context of real and simulated data sets are described. 
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{sequence analysis}
\kwd{transcriptional regulation}
\kwd{deep mutational scanning}
\kwd{mutual information}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%

% Information on figures
% http://www.biomedcentral.com/authors/figures
% width of 85 mm for half page width figure
% width of 170 mm for full page width figure
% maximum height of 225 mm for figure and legend

%%%
%%% Introduction
%%%
\section*{Introduction}

Ultra-high-throughput DNA sequencing is being used to do far more than just sequence genomes \cite{Shendure:2012et}. One rapidly growing area of application is the high-resolution measurement of  the quantitative sequence-function relationships that govern how specific sequences of interest work. A variety of ``massively parallel'' experimental methods have already been described for dissecting the functional architecture of transcriptional regulatory sequences \cite{Haberle:2012ec,White:2015eta,Inoue:2015cs} and for mapping functional domains and residues within proteins \cite{Fowler:2014gq}. 

%
% Figure 1
%
\begin{figure}[h!]
\caption{
\csentence{Various massively parallel experiments.}
(A) The ``Sort-Seq'' assay of \cite{Kinney:2010tn}. Mutagenized promoters are used to drive the expression of a fluorescent protein (green). Cells carrying expression constructs are sorted in ``bins'' according to measured fluorescence using FACS, after which the mutant promoters found in each bin of sorted cells are sequenced. (B) The ``massively parallel reporter assay'' of \cite{Melnikov:2012dw}. Variant enhancers are used to drive the transcription of RNA that contains enhancer-specific tags. Expression constructs are transfected into cell culture, after which tag-containing RNA is isolated and sequenced. Output sequences consist of the variant enhancers that correspond to expressed tag. (C) The ``deep mutational scanning'' assay of \cite{Fowler:2010gt}. Randomly mutagenized proteins (colored bells) that bind a ligand (brown circles) are expressed on the surface of phage (gray rectangle). Panning is used to enrich for phage that bind this ligand of interest. The variant proteins enriched after multiple rounds of panning are sequenced. 
}
\label{fig:experiments}
\end{figure}

Sort-Seq (Fig.\ 1A) was the first massively parallel assay described for dissecting transcriptional regulatory sequences in living cells \cite{Kinney:2010tn}. Starting with a library consisting of a randomly mutagenized version of a specific bacterial promoter, Sort-Seq is able to measure the transcriptional activity of thousands to millions of these variant promoters. This is accomplished by coupling fluorescence-activated cell sorting (FACS) to ultra-high-throughput DNA sequencing. From these data one can identify functional binding sites, quantitatively model the sequence specificities of the proteins that bind these sites, and infer quantitative biophysical models for how the wild type promoter functions \cite{Kinney:2010tn}. Similar experiments have been performed in yeast \cite{Sharon:2012io}.

Multiple ``massively parallel reporter assays'' (MPRAs) \cite{Melnikov:2012dw,Patwardhan:2012hy,Kwasnieski:2012hu} have been described for dissecting the functional architecture of enhancers in mammalian cells (Fig.\ 1B). These approaches have their origin in \cite{Patwardhan:2009cw}, which used a similar method to dissect promoter function \textit{in vitro}. Mutant versions of a specific enhancer of interest are used to drive the expression of RNA transcripts that include enhancer-specific barcodes, or ``tags.'' Expression constructs are introduced into cells, after which RNA is extracted and expressed tags are sequenced. This provides a measurement of the transcriptional activity of each variant enhancer. Such experiments can be performed in cell culture \cite{Melnikov:2012dw}, in dissected tissue \cite{Kwasnieski:2012hu}, or in the organs of living animals \cite{Patwardhan:2012hy}.

A variety of ``deep mutational scanning'' (DMS) experiments have been described for dissecting the functional features of proteins \cite{Fowler:2014gq}. Fig.\ 1C illustrates the earliest such study \cite{Fowler:2011js}. To identify which regions of a specific protein were responsible for binding a target ligand, phage expressing mutant versions of this protein on their surface were grown. Phage that bound this ligand were enriched using multiple rounds of ``panning'' and then sequenced. DMS experiments using a wide range of selection procedures tailored to different protein activities of interest have since been described \cite{Fowler:2014gq}. 

The software available for analyzing data from massively parallel experiments such as these is limited. Indeed virtually all of these experiments, including those of the authors \cite{Kinney:2010tn,RazoMejia:2014fo}, have thus far been analyzed using custom scripts. To our knowledge, two packages have been described for analyzing DMS experiments: Enrich \cite{Fowler:2011js} and DMS Tools \cite{Bloom:2015jz}. Both of these packages provide routines for estimating and visualizing per-nucleotide enrichment of pre- and post-selected sequences. However, there is far more that one can (and should) do when analyzing data from massively parallel experiments on  mutagenized sequences. 

%
% Figure 2
%
\begin{figure}[h!]
\caption{
\csentence{A common form for massively parallel experiments on  mutagenized sequences.}
(A) In all these experiments a ``library'' is generated by introducing random mutations into a specific ``wild type'' sequence of interest (blue). Library sequences are used as input to an experiment (black box) that outputs these sequences into one or more ``bins;'' library sequences are assigned to bin 0 by convention. A subset of sequences in each bin (opaque sequences) are then sequenced.  (B) The resulting data consist of two or more bins of variant sequences. Sort-Seq Tools provides routines for dealing with such data, including routines for preprocessing, simulation, quality control, sequence analysis, and quantitative modeling. Convenient visualization methods are also provided.
}
\label{fig:form}
\end{figure}

Here we describe a software package, called Sort-Seq Tools, for analyzing data from massively parallel experiments performed on libraries of  mutagenized sequences. Specifically, Sort-Seq Tools is designed as a fast and easy-to-use suite of functions for analyzing any massively parallel experiment that has the general form depicted in Fig.\ 2A. The functionality of Sort-Seq Tools is summarized in Fig.\ 2B: methods are provided for analyzing data that consists of multiple lists (one for each bin) of sequences that differ from a specific sequence of interest by randomly scattered substitution mutations.\footnote{In particular, all sequences are assumed to have the same length.} Sort-Seq Tools includes methods for performing quality control analysis, basic sequence analysis, and modeling of quantitative sequence-function relationships. Data preprocessing routines are also provided. Methods for simulating a variety of massively parallel experiments are also included; these simulation tools can be used to aid in experimental design, or to test the capabilities of analysis pipelines. 

We now provide a step-by-step elaboration of the functionality of Sort-Seq Tools. In particular, we demonstrate the capabilities of this software on the Sort-Seq data of \cite{Kinney:2010tn}, the MPRA data of \cite{Melnikov:2012dw}, and the deep mutational scanning data of \cite{Fowler:2010gt}. The simulation capabilities of Sort-Seq are also demonstrated and used to evaluate the multiple methods of quantitative model inference. Figs.\ 3-10 illustrate these analyses, as well as the specific commands used to perform them. Sort-Seq Tools is available as open source software at \texttt{https://github.com/jbkinney/15\_sortseqtools}; the data sets used in these analyses and the scripts used to produce the figures herein are included in this repository. Sort-Seq Tools is also available as the python module \texttt{sortseq}, available from PyPI.

%%%
%%% Methods and Results
%%%
\section*{Methods and Results}

%
% Overview
%
\subsection*{Overview}

%
% Figure 3
%
\begin{figure}[h!]
\caption{
\csentence{Example analysis using Sort-Seq Tools.}
(A) The Sort-Seq Tools function \texttt{profile\_freqs} transforms $\texttt{data.txt}$, a single column list of transcription factor binding sites, into \texttt{freqs.txt}, a list of nucleotide occurrence frequencies at each position in the alignment. The Sort-Seq Tools function \texttt{draw --logo} provides a sequence logo visualization of \texttt{freqs.txt}. (B) Command line implementation of the analysis in (A). Every Sort-Seq Tools method is a subcommand of the function \texttt{sortseq}. (C) Sort-Seq Tools commands can be piped in series. (D) Analysis using Sort-Seq Tools can also be performed in Python via the \texttt{sortseq} package.
}
\label{fig:demo}
\end{figure}

Sort-Seq Tools provides set of transform tabular text files of one type into tabular text files of another. An example of this is given in \fig{fig:demo}{A}. Here, a table $\texttt{data.txt}$ contains a list of aligned DNA binding sites for the \textit{Drosophila melanogaster} transcription factor hunchback. The Sort-Seq Tools function \texttt{profile\_freqs} transforms this table into a second table, \texttt{freqs.txt}, that lists the occurrence frequencies of each nucleotide at each position within the alignment. 

Sort-Seq Tools also provides a single function, \texttt{draw}, for visualizing the contents of tabular text files. The specific columns in the text file, together with optional flag aguments, determine how the tabular data is interpreted graphically. 
For instance, in \fig{fig:demo}{A}, the function \texttt{draw --logo} then transforms \texttt{freqs.txt} into a sequence logo \cite{Schneider:1990ub} using the WebLogo package \cite{Crooks:2004do}. The resulting graphics are stored as a .PDF file. 

The functionality of Sort-Seq is primarily designed to be used at the command-line, and every method is implemented as a subcommand of the function \texttt{sortseq}. For example, \fig{fig:demo}{B} shows the commands used to perform the analysis illustrated in \fig{fig:demo}{A}. For many such analysis, commands can be piped together in series (\fig{fig:demo}{C}). This reduces the need for temporary files and can speed up exploratory data analysis. 

Alternatively, Sort-Seq Tools can be used from within Python  via the \texttt{sortseq} package, which is available on PyPI. Indeed, the command line function \texttt{sortseq} is a wrapper for functions in the \texttt{sortseq} Python package. \fig{fig:demo}{D} illustrates Python code equivalent to the command line analysis of \fig{fig:demo}{B and C}. When used from inside Python, the methods of Sort-Seq Tools use \texttt{pandas} data frames instead of tabular text files. 

A key aspect of Sort-Seq Tools is its open format. Aside from \texttt{draw}, each function both inputs and outputs a human-readable table. It is therefore possible to grab any intermediate file in a Sort-Seq Tools analysis and analyze it using custom software. It is also possible to use isolated functions in Sort-Seq Tools within other pipelines. 

The tables inputted and outputted by Sort-Seq Tools must have appropriate column labels. For instance, the labels ``\texttt{pos},'' ``\texttt{freq\_A},'' etc. alert \texttt{draw} that the table provided is a list of DNA nucleotide frequencies and may therefore be visualized as a sequence logo. Table \ref{table:columns} lists the labels recognized in the current Sort-Seq Tools. Label modifiers, such as ``\texttt{\_A}'' in ``\texttt{freq\_A},'' are preceded by an underscore.

\begin{table}[h!]
\caption{Table column labels recognized by Sort-Seq Tools.}
\begin{tabular}{l|l}
Header &  Description \\ \hline \hline
\texttt{bin}            & number of sequence bin (0, 1, 2, ...) \\
\texttt{file}           & name of file containing sequence or tag data \\
\texttt{ct}             & count of sequence or tag occurrences  \\
\texttt{seq}            & sequence of DNA  (default), RNA (\texttt{\_rna}), or protein (\texttt{\_pro}) \\
\texttt{tag}            & expression tag \\
\texttt{pos}            & nuclotide/residue position within a set of aligned sequences \\
\texttt{wt}             & wild-type nucleotide or residue \\
\texttt{obs}            & observed nucleotide or residue \\ 
\texttt{mut}            & mutation rate \\
\texttt{le}             & log enrichment \\
\texttt{freq}           & occurrence frequency of nucleotide/residue \\
\texttt{val}            & model parameter  \\
\texttt{lr}             & log ratio \\
\texttt{info}           & mutual information in bits \\ 
\texttt{\_0, \_1 ...}  & associated bin number \\
\texttt{\_A, \_C ...} & associated nucleotide or residue \\
\texttt{\_err}          & estimated uncertainty 
\end{tabular}
\label{table:columns}
\end{table}

%
% Quality Control
%
\subsection*{Quality Control}

%
% Figure 4
%
\begin{figure}[h!]
\caption{
\csentence{Library quality control.}
(A) \texttt{library.txt} contains library sequence data from \cite{Kinney:2010tn}; listed are sequences and corresponding occurrence counts. (B) Pipeline for computing the per-base mutation rate: \texttt{profile\_counts} computes base occurrences at each nucleotide position; \texttt{profile\_mutrate} then computes position-specific mutation rates; \texttt{draw} then plots these mutation rates. (C) \texttt{draw} applied directly to \texttt{library.txt} yields a Zipf plot illustrating library diversity. (D) The commands used to perform these analyses. 
}
\label{fig:qc}
\end{figure}

The sequence data files used as input to Sort-Seq Tools functions are tabular text files containing one ``\texttt{seq}'' column that lists the sequences observed and one (optional) ``\texttt{ct}'' column, which lists the number of times each sequence was observed. \fig{fig:qc}{A} shows a file, \texttt{library.txt}, that contains library sequences from the Sort-Seq experiments of \cite{Kinney:2010tn}. We now illustrate how Sort-Seq Tools can be used to perform various quality controls test on such data. To make the pipelines discussed from here on more compact, we will often illustrate tables using only their column labels.

This sequence library from \cite{Kinney:2010tn} was designed to have a uniform 12\% mutation rate within the region of interest. \fig{fig:qc}{B} illustrates a pipeline for verifying this library composition.  First, the Sort-Seq Tools command \texttt{profile\_counts} is used to count the number of occurrences of each base at each position within the aligned sequences of \texttt{library.txt}. These counts are saved to \texttt{counts.txt}. Next, \texttt{profile\_mutate} is used to determine the mutation rate at each position, which is saved to \texttt{mutate.txt}.\footnote{For convenience, the wild type base at each position is assumed to be the most frequent base; this behavior, however, can be overridden by manually specifying the wild type sequence via the \texttt{--wt} flag.} Both the estimated mutation rate (\texttt{mut}) and the uncertainty in this estimate (\texttt{mut\_err}) are computed. Finally, the mutation profile in \texttt{mutate.txt} is illustrated with \texttt{draw}. From this we see that the measured mutation rates are indeed approximately 12\%. 

The position-specific mutation rate does not, however, reveal how diverse the library is. Sort-Seq Tools makes it easy to check this, however, using the \texttt{draw} command. Applied directly \texttt{library.txt}, this command returns a Zipf plot of sequence counts versus rank order. In this way we are able to verify that the library indeed contains [SHOULD SEE TOTAL NUMBER OF SEQUENCES] and is not dominated by a large number of counts for very few sequences. We emphasize that the libraries used in massively parallel experiments can easily loose diversity due to unforeseen experimental problems, and it is important to check  whether this has occurred.  

%
% Sequence analysis
%
\subsection*{Sequence analysis}

%
% Figure 5
%
\begin{figure}[h!] 
\caption{
\csentence{Information footprints.} Shown is the pipeline for performing the information footprint computations in \cite{Kinney:2010tn}. 
(A) Sort-Seq data from \cite{Kinney:2010tn} is distributed among ten files: \texttt{library.txt}, \texttt{bin\_1.txt},...,\texttt{bin\_9.txt}. (B) To collate these files, we prepare the list of files shown in \texttt{files.txt}. (C) This file list (\texttt{files.txt}) is transformed by \texttt{gatherseqs} into a single data file (\texttt{data.txt}), which lists the counts in each bin for each unique sequence. The data file (\texttt{data.txt}) is then transformed by \texttt{profile\_info} into an information footprint (\texttt{info.txt}). The \texttt{draw} then renders a graphical information footprint from \texttt{info.txt}. Note that information is quantified in the familiar units of ``bits.'' (D) The known binding sites of CRP and of RNAP are evident in the information footprint computed in (C). (E) The Sort-Seq Tools commands used to perform this analysis. 
}
\label{fig:info}
\end{figure}

The first things one typically wishes to learn from massively parallel experiments like those in \fig{fig:experiments}{} is the location of functional nucleotides or residues within the wild type sequence. A convenient way to identify these locations is to compute ``information footprints,'' which quantify how much information the identity of the nucleotide or residue at each position carries about the bin in which the sequence is found \cite{Kinney:2010tn}. 

Here we show how Sort-Seq Tools can be used to compute information footprints. This is demonstrated on Sort-Seq data from \cite{Kinney:2010tn}. This experiment assayed randomly mutated versions of a 75 bp region of the \textit{lac} promoter of \textit{E.\ coli}. This experiment yielded ten bins of sequences with bin 0 containing sequences from the unsorted library. In analyzing this data set, we begin with the ten files illustrated in \fig{fig:info}{A}. Each of these files is a list of sequences with corresponding counts.

To process these data we need one additional file, \texttt{files.txt}, which lists each bin number along with the name of the file that contains the associated data (\fig{fig:info}{B}). Next, we pass \texttt{files.txt} as input to the Sort-Seq Tools function \texttt{gatherseqs}, which returns a dataset file ,\texttt{data.txt} listing  each unique sequence along with the number of times it was observed in each bin. 

Next, \texttt{data.txt} is used as input to the Sort-Seq Tools function \texttt{profile\_info}, which outputs an \texttt{info.txt} file that lists the mutual information in bits (\texttt{info} column) at each position (\texttt{pos} column), along with the estimated uncertainty in this information value (\texttt{info\_err} column). Passing \texttt{info.txt} to the \texttt{draw} command then produces the desired information footprint. 

The \textit{lac} promoter of \textit{E.\ coli} has two functional binding sites within the 75bp region probed by the Sort-Seq experiments of \cite{Kinney:2010tn}: one binding site for the $\sigma^{70}$ RNA polymerase holoenzyme (RNAP), and one binding site for the transcription factor CRP. Both proteins read out their binding sites in a bipartite way, illustrated in \fig{fig:info}{D}. This sequence readout is well reflected in the information footprint produced by the Sort-Seq Tools pipeline in \fig{fig:info}{C}. 

%
% Figure 6
%
\begin{figure}[h!]
\caption{
\csentence{Enrichment analysis.}
Shown is the pipeline for computing enrichment profiles from DMS data as in \cite{Fowler:2010gt}. (A) First, the collated set of DNA sequence data (\texttt{dnadata.txt}) is transformed into protein sequence data (\texttt{proteindata.txt}) using the \texttt{convertseqs} command with the \texttt{--protein} flag. Next, the command \texttt{profile\_enrichment} computes log enrichment ratios for each possible amino acid / stop codon at each position (\texttt{enrichment.txt}). This enrichment profile is visualized with \texttt{draw}. (B) The Sort-Seq Tools commands used to perform this analysis.
}
\label{fig:protein}
\end{figure}

The computation of ``enrichment ratios'' is a common type of analysis in the context of deep mutational scanning experiments (see \cite{Fowler:2014gq}). Here we illustrate how to compute enrichment profiles using the data from \cite{Fowler:2010gt}. This experiment probed how the binding affinity of WW domains for the peptide ligand (GTPPPPYTVG) depends on WW domain sequence. To do this, phage-displayed WW domain proteins were selected using serial rounds of panning. Protein coding sequences recovered after either three rounds (bin 1) or six rounds (bin 2) of panning were sequenced. The enrichment among selected sequences versus library sequences of each possible amino acid / stop codon at each position was then computed.   Here we use Sort-Seq Tools to compute the enrichment profile of bin 2 relative to the library (bin 0). 

\fig{fig:protein}{A} shows the pipeline used to compute this enrichment profile. We start from a collated data file \texttt{dnadata.txt}, which can be constructed from individual data files using  \texttt{gatherseqs} as in \fig{fig:info}{}. This collated data file lists how many time each DNA coding sequence was observed in each bin. We convert these DNA sequences to peptide sequences using the command \texttt{convertseqs}, which requires an additional flag (\texttt{--protein} or \texttt{--rna}) indicating the type of target sequence. Next, we profile the enrichment in bin 2 relative to bin 0 by using the \texttt{profile\_enrichment} command. The enrichment profile lists the wild type amino acid / stop codon at each position (\texttt{wt} column) as well as the log enrichment of each of the twenty one amino acid / stop codon possibilities (\texttt{le\_A}, ..., \texttt{le\_Y}, \texttt{le\_*} columns). The command \texttt{draw} provides a quick illustration of this enrichment profile. 

%
% Figure 7
%
\begin{figure}[h!]
\caption{
\csentence{Tag expression analysis.}
Shown is the pipeline for computing log expression values from MPRA data as in \cite{Melnikov:2012dw}.
Input to the pipeline consists of (A) tag sequencing data in \texttt{library.txt} and \texttt{expression.txt}, (B) A list of data files, \texttt{files.txt}, and (C) a file \texttt{key.txt} associating each tag with a unique sequence. (D) The file list and tag key are transformed by \texttt{gatherseqs} into a collated data set, \texttt{data.txt}. \texttt{logratios} then computes log count ratio between bin 1 and bin 0 that is observed each tag (\texttt{lr.txt}). Finally, \texttt{errfromtags} computes the standard deviation in the log ratio value for each unique sequence. (E) The Sort-Seq Tools commands used to perform this analysis. 
}
\label{fig:tags}
\end{figure}

The quantification of enrichment ratios for entire sequences is also common. This is especially true in the analysis of massively parallel reporter assays (MPRAs), in which the primary data contains lists of enhancer-specific tags, not the enhancers themselves. Sort-Seq Tools provides simple methods for analyzing such data. \fig{fig:tags}{} illustrates these methods on the MPRA data of \cite{Melnikov:2012dw}. We note that Sort-Seq Tools does not require, for this analysis, that all assayed sequences be identical in length; identical length sequences are required \emph{only} when computing profiles (e.g. information footprints) or when fitting quantitative models (discussed below). 

The input to this analysis pipeline is as follows. The raw sequence data is in two files, \texttt{library.txt} and \texttt{expression.txt}, which contain a list of sequence tags and associated counts for both the library and expression data sets (\fig{fig:tags}{A}). A separate file, \texttt{files.txt}, lists these files and their associated bin numbers (\fig{fig:tags}{B}). Finally a tag key file, \texttt{key.txt}, associates each tag to a single enhancer sequence (\fig{fig:tags}{C}). Note that each enhancer sequence will typically be associated with multiple tags; this allows for independent measurements of each enhancer within the same experiment, and also ameliorates possible tag-specific artifacts. 

The Sort-Seq Tools function \texttt{gatherseqs} is used to collate counts for each tag across the different bins. Passing the file \texttt{key.txt} to this function via the \texttt{--tagkey} flag allows \texttt{gatherseqs} to include in this collated counts file the specific enhancer sequences associated with each tag. Next, the \texttt{logratios} command transforms this list of counts into a list of the log of the ratio of counts in bin 1 versus bin 0. Finally, the command \texttt{errfromtags} computes, for each unique enhancer sequence, the standard deviation in these log ratio values (specified by the \texttt{--var} flag) across all of the associated tags. The result is a list of the log ratio enrichment value and associated error for each assayed enhancer sequence. 


%
% Quantitative modeling
%

\subsection*{Quantitative modeling}

%
% Figure 8
%
\begin{figure}[h!]
\caption{
\csentence{Quantitative modeling.}
Shown is a pipeline for learning matrix models of transcription factor specificity from the Sort-Seq of \cite{Kinney:2010tn}. 
(A) Starting from the collated data set \texttt{data.txt} from \fig{fig:info}{C}, the command \texttt{learn\_matrix} uses least squares regression to fit a matrix model to data. Models that span subsequences are specified by the \texttt{--start} and \texttt{--end} flags; the interval specified here encompasses the CRP binding site. By default \texttt{draw} yields a heat map representation of the resulting model; a sequence logo representation is generated using the \texttt{--logo} flag. (B) The Sort-Seq Tools commands used to perform this analysis. 
}
\label{fig:model}
\end{figure}

Moving beyond basic sequence analysis, data from massively parallel experiment presents exciting opportunities for learning precise quantitative models of sequence-function relationships. One particularly pressing problem in molecular biology is understanding the sequence specificity of transcription factors for their DNA binding sites.  Sort-Seq Tools provides streamlined methods for learning such models from massively parallel experiments. \fig{fig:model}{} illustrates the inference of such ``matrix'' models of transcription factor specificity using the Sort-Seq data of \cite{Kinney:2010tn}. 

Using the collated data set \texttt{data.txt} from \fig{fig:info}, we need only run the command \texttt{learn\_matrix} to infer a matrix model. The flags \texttt{--start} and \texttt{--end} specify which (inclusive) positions this sequence the matrix will span. The output is a matrix model, \texttt{crp\_model.txt}, which contains a list of values contributing to this score, one value for each possible base at each position.\footnote{The score assigned to each binding site is computed as a sum of the individual contributions from each base at each position. Higher scores are interpreted as indicating higher affinity sites, although it should be emphasized that the exact interpretation will depend on what experiment was performed. These scores are defined only up to an arbitrary multiplicative scale.} By default, the \texttt{draw} command displays such matrix models in the form of a heat map. As in \fig{fig:demo}, adding the \texttt{--logo} tag will cause Sort-Seq Tools to instead render a sequence logo interpretation of this model. The model shown in \fig{fig:model}{A} illustrates the sequence specificity of the CRP transcription factor. 

It should be emphasized that there are multiple methods for learning matrix models from massively parallel data. If data consists of only two sequence bins, one bin containing library sequences and the other containing selected sequences, then the simplest method for learning matrix models is to use the approach of Berg and von Hippel \cite{Berg:1987wu,Berg:1988td} (see also \cite{Stormo:2000uw}). This inference approach is triggered by use of the \texttt{--bvh} flag. 

Alternatively, models can be fit to data using least squares regression, as was done in \cite{Melnikov:2012dw}. This requires more computation, but can still be performed rapidly. Unlike the Berg and von Hippel approach, linear regression inference naturally accommodates the use of more than two bins. This approach is triggered by use of the \texttt{--leastsq} flag (it is also the default behavior). 

The least biased method of model inference is mutual information maximization \cite{Kinney:2014ge,Atwal:2015wl}. This approach, which was used to fit models to Sort-Seq data in \cite{Kinney:2010tn}, can be invoked by using the \texttt{--mi} flag. Unlike least squares regression, mutual information maximization does not implicitly assume a specific model for experimental noise. This causes the resulting models to be less biased. However, maximizing mutual information requires a Monte Carlo optimization procedure that takes substantially longer to compute than does least squares regression. 

%
% Figure 9
%
\begin{figure}[h!]
\caption{
\csentence{Assessing model performance.}
(A) \texttt{predictiveinfo} computes the mutual information (in bits) between the sequence-dependent predictions of a model (\texttt{model.txt}) and the bin that each sequence in a specified data set (\texttt{data.txt}) is assigned to. (B) Command line instantiation of the pipeline in (A). To perform a cross-comparison of multiple models on multiple datasets, one must specify (C) a list of collated data set files (\texttt{datasets.txt}) and (D) a list of models (\texttt{models.txt}). (E) The command \texttt{compare\_predictiveinfo} computes the predictive information of each specified model on each specified dataset. (F) The \texttt{draw} command plots, for each data set, these predictive information of each model as a fraction of the predictive information of the best performing model. The cross-comparison shown reproduces results from Fig.\ S7 of \cite{Kinney:2010tn}. 
}
\label{fig:assessment}
\end{figure}

The ultimate test of model performance, of course, is the ability of a model to predict data that it was not trained on. Sort-Seq Tools provides commands for rapidly assessing model performance in this way. \fig{fig:assessment}{A} illustrates the command \texttt{predictive info}, which computes the mutual information between the predictions of a model (supplied as standard input) on any dataset of choice (supplied through the flag \texttt{--dataset}). The output is a two-line text file reporting the mutual information between model predictions and and measurements in the dataset provided. 

To cross-compare multiple models on multiple datasets, Sort-Seq Tools provides the \texttt{compare\_predictive\_information} function \fig{fig:assessment}{E}. To use this, one specifies a list of data files (each file containing a collated data set; \fig{fig:assessment}{C}) and a separate list of model files (\fig{fig:assessment}{D}). 

The output from this cross-comparison, as illustrated by the \texttt{draw} command, is shown in \fig{fig:assessment}{F}. In particular, this figure illustrates that the model of CRP binding specificity learned from the ``full-0'' dataset of \cite{Kinney:2010tn} performs much worse on other data sets from this reference than do the CRP models learned from the other data sets. Indeed, this is exactly what is expected based on the biology of the system: the ``full-0'' experiment of \cite{Kinney:2010tn} was performed in the absence of cAMP, a small molecule required by CRP for DNA binding. In the ``full-0'' experiment there was no active CRP in the cell, and thus the ``full-0'' dataset provides no real information about CRP specificity. 

%
% Simulation
%
\subsection*{Simulation}

%
% Figure 10
%
\begin{figure}[h!]
\caption{
\csentence{Data simulation.}
(A) Illustration of and (B) pipeline for a simulated Sort-Seq experiment. Given a wild type sequence, \texttt{simulate\_library} simulates a sequence library (\texttt{library.txt}). \texttt{simulate\_sort} then partitions sequences from this library into bins (using three bins by default). Specifically, a matrix model \texttt{matrix.txt} is used to assign scores to each sequence, Gaussian random noise is added to this score, and thresholding is used to assign each sequence to a bin. (C) The Sort-Seq Tools commands used to perform this analysis.  
}
\label{fig:simulation}
\end{figure}

Sort-Seq Tools also includes methods for simulating Sort-Seq, MPRA, and DMS experiments. Such simulations are useful for testing the capabilities of analysis pipelines. For instance, This information, in turn, can be used to inform experimental design. 

This simulation capability is illustrated in \fig{fig:simulation}{A,B}. Starting from a wild type sequence, the \texttt{simulate\_library} command is used to create a library of sequences (\texttt{library.txt}). The method \texttt{simulate\_sort} is then used to simulate a Sort-Seq experiment using an exiting model stored in \texttt{model.txt} and illustrated in \fig{fig:simulation}{A}. The \texttt{simulate\_sort} command has a variety of options and flags that allow the user to adjust the number of bins, the noise in the simulated fluorescence measurements, etc.. The output of this command is a collated data set, \texttt{simdata.txt}, that can be used for the same types of downstream analyses as experimental data. Other methods for simulating MPRA experiments and DMS experiments are also provided. 

%Specifically, let $a_{bi}$ be the score contribution from base $b$ occurring at position $i$, let $f^1_{bi}$ be the empirical occurrence frequency of base $b$ at position $i$ in bin 1, and define $f^0_{bi}$ analogously. The prescription of Berg and von Hippel says to set this score equal to
%\bea
%a_{bi} = \log \left( \frac{f^1_{bi}}{f^0_{bi}} \right).
%\eea
%
%Alternatively, the scores $a_{bi}$ can be fit to data using linear regression: in this case, the $a_{bi}$ values are chosen so as to minimize the quantity
%\bea
%\sum_{n} \left( B_n - \sum_{i,b} a_{bi} s^n_{bi} \right)
%\eea
%where $B_n$ is the number bin in which sequence number $n$ was found, and $s_{bi}^n \in \set{0,1}$ indicates whether base $b$ occurs at position $i$ within sequence $n$. Unlike in the Berg and von Hippel approach, this prescription 
%
%The \texttt{draw} command renders this energy matrix 

%\newenvironment{myfont}{\fontfamily{\ttdefault}\selectfont}{\par}
%
%\begin{table}[h!]
%\caption{Data processing commands}
%\begin{myfont}
%\begin{tabular}{l|lll|lllll}
%\textsf{Command}                  & \multicolumn{3}{l|}{\textsf{Input columns}} & \multicolumn{5}{l}{\textsf{Output columns}} \\ \hline \hline
%gatherseqs                        & bin    & file  &                            & ct\_0  & ct\_1    & ct\_2 ...  & seq \\
%gatherseqs --tagkey key.txt & bin & file   &                                    & ct\_0  & ct\_1    & ct\_2 ...  & tag  & seq \\
%logratios                         & ct\_0  & ct\_1 & seq                        & lr    & lr\_err   & seq \\ 
%errfromtags --var x               & x      & tag   & seq                        & x     & x\_err    & seq \\ 
%convertseqs                       & \multicolumn{3}{l|}{seq(,\_rna,\_pro)}      & \multicolumn{5}{l}{seq(,\_rna,\_pro)} \\ 
%\end{tabular}
%\end{myfont}
%\end{table}
%
%\begin{table}[h!]
%\caption{Profile generation commands}
%\begin{myfont}
%\begin{tabular}{l|llll|llll}
%\textsf{Command}        & \multicolumn{4}{l|}{\textsf{Input columns} }  & \multicolumn{4}{l}{\textsf{Output columns}} \\ \hline \hline
%profile\_counts         & ct     & seq   &           &             & pos & ct\_A   & ct\_C ...  \\
%profile\_counts --bin k & ct\_k  & seq   &           &             & pos & ct\_A   & ct\_C ...  \\
%profile\_freqs          & ct     & seq   &           &             & pos & freq\_A & freq\_C ...\\
%profile\_freqs --bin k  & ct\_k  & seq   &           &             & pos & freq\_A & freq\_C ...\\
%profile\_enrichment     & ct\_0  & ct\_1 & seq       &             & pos & le\_A   & le\_C ...  \\
%profile\_mutrates       & ct     & seq   &           &             & pos & mut     & mut\_err  \\
%profile\_info           & ct\_0  & ct\_1 & ct\_2 ... & seq         & pos & info    & info\_err \\ 
%fromto\_mutrates        & pos    & ct\_A & ct\_C ... &             & wt  & obs     & mut       & mut\_err 
%\end{tabular}
%\end{myfont}
%\end{table}
%
%\begin{table}[h!]
%\caption{Modeling commands}
%\begin{myfont}
%\begin{tabular}{l|llll|llll}
%\textsf{Command}                & \multicolumn{4}{l|}{\textsf{Input columns}}  & \multicolumn{3}{l}{\textsf{Output columns}} \\ \hline \hline
%learn\_matrix --bvh             & ct\_0  & ct\_1 & seq        &                    & pos  & val\_A    & val\_C ...  \\
%learn\_matrix --leastsq         & ct\_0  & ct\_1 & ct\_2 ...  & seq                & pos  & val\_A    & val\_C ...  \\
%learn\_matrix --MImax         & ct\_0  & ct\_1 & ct\_2 ...  & seq                & pos  & val\_A    & val\_C ...  \\
%predictiveinfo --model m       & ct\_0  & ct\_1 & ct\_2 ...  & seq                & info & info\_err \\
%totalinfo                       & ct\_0  & ct\_1 & ct\_2 ...  & seq                & info & info\_err \\
%\end{tabular}
%\end{myfont}
%\end{table}
%
%\begin{table}[h!]
%\caption{Simulation commands}
%\begin{myfont}
%\begin{tabular}{l|lll|llll}
%\textsf{Command}         & \multicolumn{3}{l|}{\textsf{Input columns}} & \multicolumn{4}{l}\textsf{Output columns} \\ \hline \hline
%simulate\_library        &    &     &                                  & ct    & seq   \\
%simulate\_library --tags &    &     &                                  & ct    & tag   & seq      \\               
%simulate\_sublib         & ct & seq &                                  & ct    & seq   \\
%simulate\_sort           & ct & seq &                                  & ct\_0 & ct\_1 & ct\_2 ... & seq \\
%simulate\_selection      & ct & seq &                                  & ct\_0 & ct\_1 & seq       \\
%simulate\_expression     & ct & tag & seq                              & ct\_0 & ct\_1 & tag       & seq \\
%\end{tabular}
%\end{myfont}
%\end{table}


%\subsection*{Analysis of simulated data}
%
%    As discussed in Figure 9, mutated libraries and data sets can be simulated for
%Sort-Seq, MPRA, and protein selection experiments. In Figure 10, it is shown that we can
%consistently recover, using our fitting methods, the models used to generate the
%simulated data sets.
%
%\subsection*{Analysis of Sort-Seq data from Kinney et al.\ (2010)}
%    Each bin of sequences is first tested for quality using the \texttt{profile\_mutrate},
%\texttt{pairwise\_mutrate}, and the \texttt{draw} functions. Each of the Kinney et al. (2010) 
%data sets showed a consitent mutation rate near to the target, which indicates that the targeted
%diversity of sequences was achieved. There was also no mutual information between one base being
%mutated and another being mutated. This is an important quality control step. If there is
%corrolation between mutation positions, then if one of the two positions has a high value on the
%information footprint, the other will as well, regardless of its importance to transcription. This
%is because in this case, knowing the identity of one base gives you information about the identity
%of a second, truly important base. The data was then analyzed by using the \texttt{profile\_info} 
%function to produce information footprints, as seen in Figure 5. The footprints allowed
%identification of the binding sites of CRP and of RNAP. Matrix models for binding energy were individually
%fit to each of these sites using mutual information maximization.
%
%\subsection*{Analysis of MPRA data from Melnikov et al.\ (2012)}
%    The \texttt{gatherseqs} function is used to connect each mRNA sequence read to the corresponding
%mutated region and combine all data into one file. This file was then analyzed using the \texttt{profile\_info}
% and \texttt{learn\_model} functions to produce information footprints and energy matrices respectively.
% Highly informative regions in the information footprint correspond to regions that are mechanistically important
%to transcription such as transcription factors or the RNAP site. Energy matrices reveal the sequence depenedence
%of the binding energy of that transcription factor. 70\% of each data set is randomly assigned to a training data set
%and 30\% is used to test the fit. The split is created using the function \texttt{train\_test\_split}. The mutual 
%information between the energy model predictions and the test data set, as calculated by the \texttt{predictiveinfo} function
% can be used as a metric for how well the model performed. 
%
%
%\subsection*{Analysis of protein mutational scanning data from Fowler et al.\ (2010)}
%
%    As discussed in Figure 9, the \cite{Fowler:2010gt,Fowler:2014gq}. data was processed and a enrichment
%profile was generated. The \texttt{learn\_model} was also used to produce an
%affinity matrix for the data set. The affinity matrix is displayed in Figure 11. 

\section*{Discussion}

Here we have described Sort-Seq Tools, a software package for the analysis of massively parallel experiments on  mutagenized sequences. This package is designed for the analysis of data from a variety of experiments, including Sort-Seq experiments on promoters, massively parallel reporter assays on enhancers, and deep mutational scanning experiments on proteins. Routines are provided for data simulation, data preprocessing, library quality control, sequence analysis, quantitative model inference, and visualization. This functionality can be accessed either at the commandline, or within the Python language via the \texttt{sortseq} module.

Sort-Seq Tools is constructed from a set of individual commands that transform tables stored as columnar text files. This open, human-readable format allows intermediate results from any stage of an analysis pipeline to be used as input to custom analysis routines. It also provides simple visualization commands which can be used to quickly illustrate the contents of many of these tables. The modeling capabilities of Sort-Seq Tools have been designed to be simple and light-weight. 

The array of massively parallel assays is rapidly expanding, and the data that these experiments produce suggests a variety of analysis tasks beyond those included in the current version package. We plan to continue improving this package. In particular, we expect to and invite the quantitative biology community to join in this effort. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

\section*{Competing interests}
The authors declare that they have no competing interests.

\section*{Author's contributions}
WI, RP, and JBK designed the research. WI and JBK wrote the software. WI and JBK wrote the paper. \ldots

\section*{Acknowledgements}
We thank Douglas Fowler for providing preprocessed DMS data from \cite{Fowler:2010gt}. We also thank Tarjei Mikkelsen for posting the preprocessed MPRA data from \cite{Melnikov:2012dw} on NCBI GEO. The work of JBK was supported by the Simons Center for Quantitative Biology at Cold Spring Harbor Laboratory. WI was supported by XXX. RP is supported by XXX.  
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{15_sortseqtools}      % Bibliography file (usually '*.bib' )

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Tables                        %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Additional Files}
  \subsection*{Additional file 1 --- Sample additional file title}
    Additional file descriptions text (including details of how to
    view the file, if it is in a non-standard format or the file extension).  This might
    refer to a multi-page table or a figure.

  \subsection*{Additional file 2 --- Sample additional file title}
    Additional file descriptions text.


\end{backmatter}

\end{document}
