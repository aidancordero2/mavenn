{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_16:0\", shape=(100, 784), dtype=float32)\n",
      "X:\n",
      "Tensor(\"Reshape_58:0\", shape=(100, 1, 784), dtype=float32)\n",
      "GX:\n",
      "Tensor(\"Reshape_59:0\", shape=(1, 20, 1), dtype=float32)\n",
      "Tensor(\"random_uniform_17:0\", shape=(100, 10), dtype=float32)\n",
      "X:\n",
      "Tensor(\"Reshape_60:0\", shape=(100, 1, 10), dtype=float32)\n",
      "GX:\n",
      "Tensor(\"Reshape_61:0\", shape=(1, 20, 1), dtype=float32)\n",
      "240.96735\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random_uniform([100, 784], minval=0, maxval=1.0)\n",
    "y = tf.random_uniform([100, 10], minval=0, maxval=1.0)\n",
    "\n",
    "GRIDS = 20\n",
    "def core_function1d(x, y, grids = GRIDS):\n",
    "    return tf.maximum((1/(grids - 1)) - tf.abs(tf.subtract(x, y)), 0)\n",
    "\n",
    "def core_function2d(x1, x2, y1, y2, grids1 = GRIDS, grids2 = GRIDS):\n",
    "    return core_function1d(x1, y1, grids1) + core_function1d(x2, y2, grids1)\n",
    "\n",
    "def entropy1d(x, grids = GRIDS):\n",
    "    shape1 = [x.get_shape().as_list()[0], 1, x.get_shape().as_list()[1]]\n",
    "    shape2 = [1, grids, 1]\n",
    "\n",
    "    gx = tf.linspace(0.0, 1.0, grids)\n",
    "    print('x: ')\n",
    "    print(x)\n",
    "    X = tf.reshape(x, shape1)\n",
    "    GX = tf.reshape(gx, shape2)\n",
    "    print('X:')\n",
    "    print(X)\n",
    "    print('GX:')\n",
    "    print(GX)\n",
    "    mapping = core_function1d(GX, X, grids)\n",
    "    #print(mapping)\n",
    "    mapping = tf.reduce_sum(mapping, 0)\n",
    "    mapping = tf.add(mapping, 1e-10)\n",
    "    mapping_normalized = tf.divide(mapping, tf.reduce_sum(mapping, 0, keepdims = True))\n",
    "\n",
    "    entropy = tf.negative(tf.reduce_sum(tf.reduce_sum(tf.multiply(mapping_normalized, tf.log(mapping_normalized * grids)), 0)))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def entropy2d(x, y, gridsx = GRIDS, gridsy = GRIDS):\n",
    "    batch_size = x.get_shape().as_list()[0]\n",
    "    x_szie = x.get_shape().as_list()[1]\n",
    "    y_size = y.get_shape().as_list()[1]\n",
    "\n",
    "    gx = tf.linspace(0.0, 1.0, gridsx)\n",
    "    gy = tf.linspace(0.0, 1.0, gridsy)\n",
    "\n",
    "    X = tf.reshape(x, [batch_size, 1, 1, x_szie, 1])\n",
    "    Y = tf.reshape(y, [batch_size, 1, 1, 1, y_size])\n",
    "\n",
    "    GX = tf.reshape(gx, [1, gridsx, 1, 1, 1])\n",
    "    GY = tf.reshape(gy, [1, 1, gridsy, 1, 1])\n",
    "\n",
    "    mapping = core_function2d(GX, GY, X, Y, gridsx, gridsy)\n",
    "    mapping = tf.reduce_sum(mapping, 0)\n",
    "    mapping = tf.add(mapping, 1e-10)\n",
    "    mapping_normalized = tf.divide(mapping, tf.reduce_sum(mapping, [0, 1], keepdims = True))\n",
    "\n",
    "    entropy = tf.negative(tf.reduce_sum(tf.reduce_sum(tf.multiply(mapping_normalized, tf.log(mapping_normalized * (gridsx *gridsy))), [0, 1])))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def matul_info(x, y):\n",
    "    ex = entropy1d(x)\n",
    "    ey = entropy1d(y)\n",
    "    exy = entropy2d(x, y)\n",
    "    return ex + ey - exy\n",
    "\n",
    "multi_info = entropy1d(x) + entropy1d(y) - entropy2d(x, y)\n",
    "with tf.Session():\n",
    "    #print(x.eval())\n",
    "    print(multi_info.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 1, 784]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.get_shape().as_list()[0], 1, x.get_shape().as_list()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_py = np.random.randn(100,784)\n",
    "y_py = np.random.randn(100,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRIDS = 20\n",
    "def core_function1d_py(x, y, grids = GRIDS):\n",
    "    return np.max((1/(grids - 1)) - abs(x-y), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,784) (100,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2acfdef21837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcore_function1d_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_py\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_py\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-9b0bd50e9e52>\u001b[0m in \u001b[0;36mcore_function1d_py\u001b[0;34m(x, y, grids)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mGRIDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcore_function1d_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRIDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrids\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,784) (100,10) "
     ]
    }
   ],
   "source": [
    "core_function1d_py(x_py,y_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_py[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "motif_learn_convnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
